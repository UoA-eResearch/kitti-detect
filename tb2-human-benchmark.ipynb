{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdcc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: current data partitioning with label overrides assumes one object per image\n",
    "\n",
    "# credit to: https://towardsdatascience.com/building-your-own-object-detector-pytorch-vs-tensorflow-and-how-to-even-get-started-1d314691d4ae\n",
    "# for initial ideas\n",
    "\n",
    "# installing key packages:\n",
    "# conda install pytorch torchvision torchaudio cudatoolkit=11.0 -c pytorch -c nvidia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4335ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5d6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "from common import parse_kitti\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef8382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_parent_path(p, parent):\n",
    "    fname = os.path.basename(p)\n",
    "    return os.path.join(parent, fname)\n",
    "\n",
    "def crop(sample, pad=0):    \n",
    "    image_path = sample['image_path']\n",
    "    label_path = sample['label_path']\n",
    "    \n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    objects = parse_kitti(label_path)                \n",
    "    boxes = np.array([o['bounds'] for o in objects], dtype=int)\n",
    "    boxes += np.array([-1, -1, 1 , 1], dtype=int) * pad\n",
    "        \n",
    "    if len(boxes) != 1:\n",
    "        print(f\"Warning: Crop only works for single objects per image at the moment\\n{sample}\")\n",
    "    \n",
    "    return img.crop(boxes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5216908a",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e5a22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment name corresponds to the foldername and file prefix for data partitions and label maps\n",
    "exp_name = \"t2b\"\n",
    "orig_image_dir = \"../data/combined/images\"\n",
    "orig_label_dir = \"../data/combined/labels\"\n",
    "\n",
    "# load train and test data partitions\n",
    "test_folds = [0, 1, 2, 3, 4]\n",
    "\n",
    "use_label_overrides = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bfeb4",
   "metadata": {},
   "source": [
    "# Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b570df04",
   "metadata": {},
   "outputs": [],
   "source": [
    "for test_fold in test_folds:\n",
    "\n",
    "    print(f'test_fold: {test_fold}')\n",
    "    train_path = f\"{exp_name}/{exp_name}-train-{test_fold}.json\"\n",
    "    test_path = f\"{exp_name}/{exp_name}-test-{test_fold}.json\"\n",
    "\n",
    "    data_train = None\n",
    "    data_test = None\n",
    "\n",
    "    with open(train_path, 'r') as f:\n",
    "        data_train = json.load(f)\n",
    "\n",
    "    with open(test_path, 'r') as f:\n",
    "        data_test = json.load(f)    \n",
    "\n",
    "    print(f\"samples: {len(data_train) + len(data_test)}, train samples: {len(data_train)}, test samples: {len(data_test)}\")\n",
    "\n",
    "    # load the label map\n",
    "    label_map_path = f\"{exp_name}/{exp_name}-label-map.json\"\n",
    "    with open(label_map_path, 'r') as f:\n",
    "        label_map = json.load(f)\n",
    "    print(f\"label map: {label_map}\")\n",
    "    reverse_label_map = {v:k for k,v in label_map.items()}\n",
    "    \n",
    "    # define datasets and data loaders\n",
    "    #batch_size = 32\n",
    "    #ds = KITTIDataset(data_train, label_map, use_label_overrides=use_label_overrides, transforms=get_transforms(train=False))\n",
    "    #ds_test = KITTIDataset(data_test, label_map, use_label_overrides=use_label_overrides, transforms=get_transforms(train=False))\n",
    "\n",
    "    #dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, num_workers=1, collate_fn=utils.collate_fn)\n",
    "    #dl_test = torch.utils.data.DataLoader(ds_test, batch_size=1, shuffle=False, num_workers=1, collate_fn=utils.collate_fn)\n",
    "    \n",
    "    # save cropped images\n",
    "    save_dir = os.path.join(exp_name, \"benchmark\")\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "    save_dir = os.path.join(save_dir, f\"{exp_name}-part-{test_fold}\")\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "        \n",
    "\n",
    "    data_test_orig = []\n",
    "    for sample in data_test:\n",
    "        sample['image_path'] = replace_parent_path(sample['image_path'], orig_image_dir)\n",
    "        sample['label_path'] = replace_parent_path(sample['label_path'], orig_label_dir)\n",
    "        data_test_orig.append(sample)\n",
    "    random.shuffle(data_test_orig)        \n",
    "\n",
    "    answers = []\n",
    "    for i, sample in enumerate(data_test_orig):        \n",
    "        img_crop = crop(sample)    \n",
    "        sample['test_idx'] = i\n",
    "        #path = os.path.join(save_dir, os.path.basename(sample['image_path']))\n",
    "        _, ext = os.path.splitext(sample['image_path'])\n",
    "        path = os.path.join(save_dir, f\"{sample['test_idx']}{ext}\")\n",
    "        img_crop.save(path)          \n",
    "        answers.append(sample)\n",
    "\n",
    "    with open(os.path.join(save_dir, f\"answers.json\"), 'w') as f:\n",
    "        json.dump(answers, f)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80246ee1",
   "metadata": {},
   "source": [
    "### Data Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491c3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = data_test_orig[222]\n",
    "# img_crop = crop(sample, pad=100)\n",
    "# plt.imshow(img_crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a1127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(Image.open('../data/combined/images/25765b.jpg').convert(\"RGB\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
