{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcda71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: current data partitioning with label overrides assumes one object per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e69c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace67055",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53069eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "data_dir = \"../data/combined/resized\"\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "label_dir = os.path.join(data_dir, \"labels\")\n",
    "\n",
    "# label overrides\n",
    "label_overrides_df = pd.read_excel('../data/labels.xlsx').fillna('')\n",
    "label_overrides = {}\n",
    "for index, row in label_overrides_df.iterrows():\n",
    "    label_overrides[str(row['ID']).strip()] = row['Tier2'].lower()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab72816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show class distribution\n",
    "image_paths = glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "cs = class_summary(image_paths, label_dir, label_overrides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e937a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51f0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a base set of image paths of all cores and tools\n",
    "p_base = [p[0] for p in cs['core']]\n",
    "p_base += [p[0] for p in cs['tool']]\n",
    "print(len(p_base))\n",
    "\n",
    "other_classes = ['flake', 'rock']\n",
    "sample_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7b8b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create partitions\n",
    "k = 5 # number of partitions\n",
    "r_test = 0.2 # test ratio\n",
    "\n",
    "n_k = (len(p_base) + len(other_classes) * sample_size) // k + 1\n",
    "parts = []\n",
    "for i in range(k):\n",
    "    \n",
    "    # generate class balanced list of images\n",
    "    p_image_paths = [] + p_base\n",
    "    for c in other_classes:\n",
    "        p_image_paths += random.sample([p[0] for p in cs[c]], sample_size)    \n",
    "    random.shuffle(p_image_paths)\n",
    "    \n",
    "    start = 0\n",
    "    end = len(p_image_paths)\n",
    "    p = p_image_paths[start:end]\n",
    "    print(f\"partition: {i+1}, start: {start}, end: {end}, count: {len(p)}\")\n",
    "    \n",
    "    # train-test split\n",
    "    n_train = int(r_test * len(p))\n",
    "    p_train = p[:-n_train]\n",
    "    p_test = p[-n_train:]\n",
    "    \n",
    "    classes_train = class_summary(p_train, label_dir, label_overrides)\n",
    "    classes_test = class_summary(p_test, label_dir, label_overrides)\n",
    "    print(\"train:\")  \n",
    "    print(\"-----------\")\n",
    "    distribution(classes_train)\n",
    "    print(\"test:\")\n",
    "    print(\"-----------\")\n",
    "    distribution(classes_test)\n",
    "    parts.append((classes_train, classes_test))\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5707a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save partitions\n",
    "exp_name = 't2b'\n",
    "if not os.path.exists(exp_name):\n",
    "    os.mkdir(exp_name)\n",
    "    \n",
    "for i, (part_train, part_test) in enumerate(parts):\n",
    "    path_train = os.path.join(exp_name, f\"{exp_name}-train-{i}.json\")\n",
    "    path_test = os.path.join(exp_name, f\"{exp_name}-test-{i}.json\")\n",
    "    save_partition(path_train, part_train)\n",
    "    save_partition(path_test, part_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbedcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label map\n",
    "label_map = {\n",
    "    'background': 0, # required\n",
    "    'rock': 1,\n",
    "    'flake': 2,\n",
    "    'tool': 3,\n",
    "    'core': 4\n",
    "}\n",
    "\n",
    "path = os.path.join(exp_name, f\"{exp_name}-label-map.json\")\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(label_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed79d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
