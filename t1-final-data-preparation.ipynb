{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424607e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221aad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load benchmark reference paths\n",
    "exp_name = \"t2b\"\n",
    "responses = {'SM': None, 'RP': None}\n",
    "benchmark_dir = os.path.join(exp_name, 'benchmark')\n",
    "answers_paths = [os.path.join(benchmark_dir, f'{exp_name}-part-{i}', 'answers.json') for i in range(5)]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae55fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load responses\n",
    "data = []\n",
    "for r in list(responses.keys()):\n",
    "    r_path = os.path.join(exp_name, 'benchmark', f'{r}.xlsx')    \n",
    "    responses[r] = pd.read_excel(r_path, header=0, index_col=0)\n",
    "\n",
    "# iterate over partitions\n",
    "for pi, part in enumerate([os.path.join(benchmark_dir,  f'{exp_name}-part-{i}') for i in range(5)]):\n",
    "    col_name = os.path.basename(part)\n",
    "    answers_path = os.path.join(part, 'answers.json')\n",
    "    \n",
    "    # load answers\n",
    "    with open(answers_path, 'r') as f:\n",
    "        answers = json.load(f)\n",
    "    \n",
    "    # append responses\n",
    "    for r in list(responses.keys()):\n",
    "        for i, a in enumerate(answers):            \n",
    "            answers[i][f'{r}'] = responses[r].iloc[i, pi].lower()    \n",
    "    \n",
    "    # append to master list\n",
    "    data += answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22daf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = pd.DataFrame.from_dict(data).dropna().drop(columns=['test_idx']).drop_duplicates(\"image_path\")\n",
    "print(benchmark.label_override.value_counts())\n",
    "print('Total', len(benchmark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85315934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "data_dir = \"../data/combined/resized\"\n",
    "image_dir = os.path.join(data_dir, \"images\")\n",
    "label_dir = os.path.join(data_dir, \"labels\")\n",
    "\n",
    "# label overrides\n",
    "label_overrides_df = pd.read_excel('../data/labels.xlsx').fillna('')\n",
    "label_overrides = {}\n",
    "for index, row in label_overrides_df.iterrows():\n",
    "    label_overrides[str(row['ID']).strip()] = row['Tier1'].lower()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6eb258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove benchmark images from training set\n",
    "training_image_prefix = '../data/combined/resized/images/'\n",
    "image_paths = glob(os.path.join(image_dir, \"*.jpg\"))\n",
    "training_image_paths = set([os.path.basename(x) for x in image_paths]) - set([os.path.basename(x) for x in benchmark['image_path'].values])\n",
    "training_image_paths = [os.path.join(training_image_prefix, x) for x in training_image_paths]\n",
    "print(len(training_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106caa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show class distribution\n",
    "random.shuffle(training_image_paths) # randomise\n",
    "distribution(class_summary(training_image_paths, label_dir, label_overrides))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a07986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create partitions\n",
    "k = 1 # number of partitions\n",
    "\n",
    "n_k = len(training_image_paths) // k + 1\n",
    "parts = []\n",
    "for i in range(k):\n",
    "    start = i * n_k\n",
    "    end = (i+1) * n_k\n",
    "    p = training_image_paths[start:end]\n",
    "    print(f\"partition: {i+1}, start: {start}, end: {end}, count: {len(p)}\")\n",
    "    classes = class_summary(p, label_dir, label_overrides)\n",
    "    distribution(classes)\n",
    "    parts.append(classes)\n",
    "    print(\"================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df07a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save partitions\n",
    "exp_name = 't1-final'\n",
    "if not os.path.exists(exp_name):\n",
    "    os.mkdir(exp_name)\n",
    "    \n",
    "for i, p in enumerate(parts):\n",
    "    path = os.path.join(exp_name, f\"{exp_name}-part-{i}.json\")\n",
    "    save_partition(path, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7544105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save label map\n",
    "label_map = {\n",
    "    'background': 0, # required\n",
    "    'rock': 1,\n",
    "    'artefact': 2,\n",
    "}\n",
    "\n",
    "path = os.path.join(exp_name, f\"{exp_name}-label-map.json\")\n",
    "with open(path, 'w') as f:\n",
    "    json.dump(label_map, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3f9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save benchmark as test set\n",
    "image_prefix = '../data/combined/resized/images/'\n",
    "benchmark_image_paths = [os.path.basename(x) for x in benchmark['image_path'].values]\n",
    "benchmark_image_paths = [os.path.join(image_prefix, x) for x in benchmark_image_paths]\n",
    "\n",
    "label_prefix = '../data/combined/resized/labels/'\n",
    "benchmark_label_paths = [os.path.basename(x) for x in benchmark['label_path'].values]\n",
    "benchmark_label_paths = [os.path.join(label_prefix, x) for x in benchmark_label_paths]\n",
    "\n",
    "# drop other cols\n",
    "test_set = benchmark.drop(columns=['SM', 'RP'])\n",
    "\n",
    "# set correct paths\n",
    "test_set['image_path'] = benchmark_image_paths\n",
    "test_set['label_path'] = benchmark_label_paths\n",
    "\n",
    "# override labels\n",
    "mask = test_set.label_override != 'rock'\n",
    "test_set.loc[mask, 'label_override'] = 'artefact'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d06548",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.label_override.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae33f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(exp_name, f\"{exp_name}-test.json\")\n",
    "with open(path, 'w') as f:\n",
    "    test_set.to_json(f, orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd3f56d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
